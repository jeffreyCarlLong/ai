---
title: "Biostats AI"
author: "Jeffrey Long"
format: html
editor: visual
---

## The Generative AI Revolution

A new wave of generative AI systems like ChatGPT, Claude, Gemini, and Microsoft Copilot can generate entirely new content—whether that's text, code, images, or even video.

They can act as tools that help you accomplish complex tasks, like vibe coding applications where you describe what you want and the AI writes the code for you.

They're built on decades of research and development, combining advances in computer science, machine learning, natural language processing, and massive computational power.

### **Different Types of Artificial Intelligence**

#### Expert Systems: Rule-Based Intelligence

Expert systems operate on hard-coded rules and logic, following explicit if-then instructions. The temperature controls in your refrigerator are an example of an expert system (e.g. refrigerator temperature - if/then conditions).

#### Machine Learning: Learning from Data

Machine learning systems learn from data to recognize patterns and trends and make predictions.

An example would be medical diagnoses, where a machine learning system can interpret medical images taken by a medical professional, and return the likelihood of a detection.

In expert systems, the rules are provided by us to translate an input into an output. In our refrigerator, the rules are simply whether the temperature goes up or down. In machine learning, established algorithms are applied to a dataset of examples to determine these rules for us. In machine learning, these learned "rules" are more often called a model, and the process of learning these rules is called "model training".

Your phone's autocorrect system has been trained on millions of keystrokes to be able to fix mistyped words.

Netflix's recommendation system is a model of your viewing habits and those of similar users to suggest content you are most likely to enjoy. In both of these cases, these systems recognize patterns learned from the data. Machine learning has unlocked tremendous potential across fields—from disease detection in healthcare to improved weather forecasting. The key difference? These systems learn from data rather than following explicit logic.

#### Generative AI

Generative AI, which emerged from technical advances in machine learning in the 2010's. While still part of the machine learning family, generative AI flips the paradigm from pattern recognition to pattern completion. Traditional machine learning takes input data and arrives at a prediction or decision—like analyzing system logs to detect a crash. Generative AI, on the other hand, attempts to complete the most likely pattern based on the input provided. When you ask a Generative AI chatbot to write a Shakespearean poem, it's completing what would naturally come next based on patterns it's learned about Shakespeare's writing style. This allows generative AI to produce entirely new data—whether that's text, images, video, music, or code. It's a fundamentally different approach that enables creative and generative capabilities we've never seen before.

### Large Language Models (LLMs): Intelligence on Demand

### Prompt Engineering

A simple four-part framework that will transform how you write prompts: Ask, Requirements, Context, and Examples.

#### the Ask

This is your core request, stated clearly. For example: 'Summarize this quarterly report for executives.' Simple and direct. Second,

#### Requirements

These are your specific constraints and preferences. You might say: 'Keep it to two paragraphs, focus on actionable insights rather than raw data, and avoid technical jargon.' Notice how this gives AI clear boundaries to work within. Third,

#### Context

This is the background information that shapes how the task should be done. 'The executives reading this are non-technical and care most about strategic implications for decision-making.' This helps AI understand the audience and adjust its approach.

#### Examples

Showing what "good" looks like. You might provide a snippet of a previous summary that hit the mark, or even show a bad example with notes on what to avoid. Examples are incredibly powerful because they demonstrate your expectations in a way that descriptions alone cannot.

### **The Power of Iterative Refinement**

Think of working with AI like sculpting clay or play-doh. The first version gives you the rough shape, but refinement adds the detail. You don’t throw the clay away—you shape it. The same principle applies here. If the first draft is weak, guide it with specific feedback.

### User Beware

-   Knowledge fabrication - key strategy is a “trust but verify” mindset. Always double-check critical information, especially in four areas: numbers and data points, citations and references, historical facts and dates, and technical details.

-   Recency ignorance - Always check what that cutoff is; most models will tell you if asked. Then, verify anything that happened afterward, especially prices, regulations, personnel changes, and news.

-   Biased Outputs

-   Sycophantic Outputs - actively guide the AI toward objectivity and critical analysis. Maintain active skepticism, especially when its response feels particularly validating.

-   Privacy and Data Exposure

## Prompt Engineering Deep Dive

Harnessing ChatGPT’s full potential requires a mix of art and science. This combination is what we call 'Prompt Engineering'. It’s all about writing inputs that maximize the quality of the output. The art lies in understanding the nuances of language, tone, and context. The science is about recognizing the model's capabilities and decoding strategies. Together, they help in sculpting the ideal prompt.

There are nuances that separate a good prompt from a great one, letting you achieve optimal responses from language models like ChatGPT. Just as there are best practices in prompt engineering, there are also pitfalls to avoid: Overloading: Bombarding the model with too much information can dilute the essence of your query. Ambiguity: Being vague can lead to generalized answers. Over-Complication: Using jargon, complex phrasing, or unnecessary technicalities can confuse the model, leading to misinterpretations or overly complex answers.

Prompts are the bridge between curiosity and knowledge. Use ChatGPT to augment, not replace, your creativity. Let it be a partnership where you break conventional thinking patterns, ushering in new ideas.

### Infusing a Persona

Instead of relying on a generic output, we can ask our trusty friend Ernest Hemingway to write a speech for us. Or we can have Shakespeare write our recipe for a vegan lunch.

This can help influence output style, audience, length and tone. Four variables we can control to help reach our desired response.

### Make it Personal

See ChatGPT craft emails that echo your personal writing style. Providing examples to ChatGPT is a great way for the model to emulate your writing style. This makes every response resonate with your unique voice.

### Use Markdown

Markdown is an elegant way of structuring text. In addition, the correct use of quotation marks and delimiters will lead to a more tailored input. These are two smart tools you can use that will help remove ambiguity from your prompt, turning a good question into a great one.

### Chain-of-Thought Training Techniques- Zero, One and Few Shot

Chain-of-thought works by getting ChatGPT to break down a task into its subsequent steps. This can be done via (i) Zero-shot. Not providing any examples and asking ChatGPT for the problem-solving guide, or (ii) One/few-shot. Providing one or more examples of a framework that ChatGPT can use to tackle the problem.

Zero Shot - "What should I watch?"

One shot - "I like Stranger Things and The Closer. What should I watch on Netflix?"

### Limitations

ChatGPT has its limitations. Understanding these conditions will help you recognise things like: Biases — The model presents stereotypes or misinformation Hallucinations — The model confidently states incorrect information Overfitting — The model is only as good as the data it's trained on Building a discerning eye for these shortcomings will help you get the most out of ChatGPT.

### Anticipate Complex Workflows

"Let's draft a startup plan focused on sustainable technology," will be our entry point into creating sophisticated, multi-part responses that mirror a strategic consultancy session. We can layer this with asks to ChatGPT for frameworks and resources that would’ve otherwise been overlooked. "Focus on solving a really tough problem the world is currently suffering from."

### Good Prompts

Effective prompts typically exhibit three distinct traits: **Clarity**: A well-defined prompt includes the relevant context to reduce ambiguity. **Specificity**: The more specific you are, the closer you get to your desired answer. And finally, **open-endedness**: Sometimes, allowing the model to think outside the box can yield richer results that were non-obvious from the outset.

LLMs can output checklists.

In the transcript from the Huberman Lab podcast titled "How to Breathe Correctly for Optimal Health, Mood, Learning & Performance", a "physiological sigh" consists of two deep inhales through the nose followed by a full exhale through the mouth. It rapidly reduces stress in real time. It is not considered a hack, but rather a natural process that the body performs during sleep and throughout the day. The effectiveness is attributed to the optimal balancing of oxygen and carbon dioxide levels in the body. - Thanks Dr. Chat.

Use this email to understand my writing style...

Now write an email to do X.

### Output Control

To simplify output control, remember our acronym: SALT. Each letter stands for a different control variable: Style — define the framework; Audience — tailoring the content; Length — brevity or depth, and Tone — covering the mood and feel.

#### Style 

Style isn't just about the format; it's about the framework of your desired response. Asking for a structured output, like a list or a step-by-step guide, can drastically change the information you receive. “Describe the solar system” might give you a paragraph, but “List the planets in the solar system” provides a clear, organised response. By shaping the style, you shape the narrative.

e.g. “Provide a list of steps I need to make the perfect blueberry pancake.”

#### Audience

Every audience is unique, with its own set of requirements. A child might need a simple, engaging explanation, while a professional might seek technical details. When we tailor our prompts to our intended audience, we ensure that the content we receive is both relevant and understandable. It's like dressing for the occasion; the content must fit the audience just right. I like to use audience controls if I’m learning a new concept and need a simple explanation. “Explain the concept of machine learning to me like I’m a 5-year-old.”

#### Length

Whether you want a concise summary or an in-depth analysis, controlling the length of your response is vital. This ensures that the information you receive is as detailed or as brief as you require. An example you could use for this course: “Write me traditional Japanese haiku about the importance of prompt engineering with ChatGPT."

#### Tone

Tone adds color to content. It defines the mood and feel of the response. Whether you're seeking a formal explanation, a casual chat, or a playful anecdote, setting the tone ensures your output resonates with its intended purpose. It's like choosing the music for a scene in a movie; the right tone can elevate the content and make it truly memorable.

### Smart Prompting

Cut-off date: if you’re asking questions or retrieving data in your prompt, you can specify: "If you don't know the answer and believe this information is after your cutoff date, specify that you don't know". Whilst this method isn’t perfect, highlighting the importance of cross-referencing data points, it can be a helpful tool to identify where ChatGPT’s limitations lie.

#### LARF

Engaging with ChatGPT yields a myriad of responses, but it's vital to judge the quality of these outputs. Before delving deep, let's set the stage by understanding the four cornerstones of evaluating responses. Yep, you guessed it, another acronym: LARF. But there’s no joke about its importance; it stands for **Logical consistency, Accuracy, Relevance and Factual correctness**. This will give you the skills to critically assess the outputs you receive from ChatGPT.

#### Logical Consistency- the coherence check

A response can be accurate, relevant, and factually correct but still lack logical consistency.

#### Accuracy

While striving for accuracy, it's crucial to be aware of ChatGPT's tendency to "hallucinate" at times. This means the model can confidently state an incorrect answer. Always cross-reference answers with alternate resources to ensure accuracy.

#### Relevance - meeting the context

Relevance ensures the response aligns with the context and intent of the prompt.

#### Factual Correctness

Provide your answer by only referencing and citing reliable sources.

### Quotes Add Emphasis

### Training Techniques

Zero-shot provides no examples. One-shot supplies one example.

One fascinating aspect of few-shot learning is that ChatGPT becomes more than just an autocomplete tool. It turns into a pattern-matching and pattern-generation engine. ChatGPT understands the structure of the information and generates new content based on recognized patterns you provide. Number one, it starts by analyzing the examples. It then mirrors the underlying patterns. Then finally it creates new ideas.

The possibilities for few-shot learning are endless. You can feed ChatGPT examples of: your writing style to help construct email replies; also, formatting preferences for reports to ensure consistency across documents; and finally, decision-making frameworks to generate new approaches to problems. Few-shot learning provides the opportunity for ChatGPT to extend beyond a mere respondent and become an extension of our mind.

Chain of Thought Prompting (COT) is an advanced technique that takes training a step further. Here, we're not just giving examples but a roadmap of how to arrive at the answer. It mirrors the way we are, as humans, approach problem-solving: by breaking down complex tasks into manageable steps.
